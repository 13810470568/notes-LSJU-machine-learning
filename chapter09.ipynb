{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第九讲：\n",
    "\n",
    "# 第六部分：学习理论（Learning Theory）\n",
    "\n",
    "## 1. 偏差/方差权衡（Bias/variance tradeoff）\n",
    "\n",
    "最早在我们学习线性回归的时候，我们就进行了关于选择拟合一个简单模型（如$y=\\theta_0+\\theta_1x$），还是选择拟合一个复杂模型（$y=\\theta_0+\\theta_1x+\\cdots+\\theta_5x^5$）的讨论，仍旧是这幅图：\n",
    "\n",
    "<img src=\"./resource/chapter09_image01.png\" width=\"800\" alt=\"\" align=center />\n",
    "\n",
    "结果发现，拟合一个五阶多项式（右图）并不是一个好的选择。而且，尽管这个五阶多项式在对训练集中的样本特征$x$（比如实用面积）做出预测$y$（比如公寓租金）时做的非常好，我们也并不看好它对不再训练集中样本的预测结果。换句话说，模型从训练集中学到的知识并不能很好的*泛化（generalize）*到其他房屋租赁样本中。我们说一个假设的**泛化误差（generalization error）**就是指该假设对于不在训练集中样本预测的期望误差（我们在后面会给出正式的定义）。\n",
    "\n",
    "最左和最右的图片都存在较大的泛化误差，但是这两个模型的问题却并不相同。如果$y$与$x$并不是线性关系，那么如果我们使用线性模型去拟合训练集，即使训练集很大，线性模型也不能精确的捕捉到数据的结构特征。非正式的定义模型的**偏差（bias）**：即模型的预测值与样本实际值之间的差距，偏差越大则约偏离真实数据，即使拟合的训练集很大（如无限的训练集）。因此，对于左图，其线性模可能型存在欠拟合问题（即不能捕捉到数据呈现出的特征）。\n",
    "\n",
    "除了偏差，泛化误差还有另一个组成部分——模型拟合过程的**方差（variance）**。比如右图中的五阶多项式，这个模型很有可能只反映出了我们这个有限训练集中的数据特征，但并不能反映出不在训练集中的更广泛的$y$与$x$的关系。我们的训练集中可能存在比平均价格更高或更低的样本，于是当我们拟合这些“具有欺骗性的”数据时，也有可能得到一个泛化误差很大的模型。在这种情况下，我们称模型具有较大的方差，也就是预测值的变化范围或离散程度较大。（方差越大，数据分布越分散。在课程中我们不再给出关于偏差与方差的形式化定义，尽管这两个概念在诸如线性回归的算法中有明确定义，但在分类问题中这些概念的定义却有好几个不同的提议，而且尚未达成共识。）\n",
    "\n",
    "参见[Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)：\n",
    "\n",
    "<img src=\"./resource/chapter09_image02.png\" width=\"500\" alt=\"\" align=center />\n",
    "\n",
    "通常，我摸在偏差与方差间都会做出权衡。如果我们的模型过于简单，只有很少的几个参数，那么它可能存在着较大的偏差（但是方差较小）；如果过于复杂而含有非常多的参数，那么模型可能会存在较大的方差（但是偏差较小）。对于上面的这个例子，使用二次函数拟合的效果优于一阶或五阶多项式。\n",
    "\n",
    "## 2. 序言\n",
    "\n",
    "本节我们会对学习理论有一个大致了解，除了启发和深入理解机器学习，这部分讨论还将加强我们对学习理论直观概念，也会介绍一些学习算法在不同设置下最佳应用的经验。同时还将尝试解答这几个问题：\n",
    "* 首先，我们能否形式化偏差与方差间的权衡过程？\n",
    "\n",
    "    这个问题也将引出关于模型选择方法的讨论，比如算法自动确定使用几阶多项式进行拟合。\n",
    "* 其次，在机器学习中我们真正关心的是模型的泛化误差，但是大多数学习算法只对训练集做拟合，那么我们如何从“对训练集有着很好拟合的模型”中得知它的泛化误差？\n",
    "\n",
    "    我们尤其想知道，能否将“模型关于训练集的误差”同“模型的泛化误差”联系起来？\n",
    "* 最后一个问题，是否存在能够证明学习算法将会有效的条件？\n",
    "\n",
    "我们从两个非常有用的引理说起：\n",
    "\n",
    "**引理**联合界（the union bound）：令$A_1,A_2,\\cdots,A_k$为$k$个不同的事件（并不要求独立），则有：\n",
    "\n",
    "$$\n",
    "P(A_1\\cup\\cdots\\cup A_k)\\leq P(A_1)+\\cdots+P(A_k)\n",
    "$$\n",
    "\n",
    "在概率论中，联合界通常当做公理来使用（所以我们不会尝试证明这个式子），不过它很符合直觉：$k$个事件中任一事件发生的概率最多不超过这$k$个事件发生的概率之和。\n",
    "\n",
    "**引理**霍夫丁不等式（Hoeffding inequality），$Z_1,\\cdots,Z_m$是服从$\\mathrm{Bernoulli}(\\phi)$的独立同分布（IID）的随机变量，即$P(Z_i=1)=\\phi,P(Z_i=0)=1-\\phi$。令$\\hat\\phi=\\frac{1}{m}\\displaystyle\\sum_{i=1}^mZ_i$为这些随机变量的期望，再令$\\gamma\\gt0$，则有：\n",
    "\n",
    "$$\n",
    "P\\left(\\lvert\\phi-\\hat\\phi\\rvert\\gt\\gamma\\right)\\leq2\\exp\\left(-2\\gamma^2m\\right)\n",
    "$$\n",
    "\n",
    "这个引理（在机器学习中也叫作切诺夫界，Chernoff bound）告诉我们，如果用$\\hat\\phi$（即$m$个服从$\\mathrm{Bernoulli}(\\phi)$的随机变量的平均值）作为参数$\\phi$的估计，那么如果$m$越大，则我们离参数实际值越接近。也就是说，假设有一枚不均匀的硬币，掷这枚硬币面朝上的概率为$\\phi$，如果我们掷$m$次硬币，然后计算面朝上的比例，那么掷的次数越多，则这个比例对参数$\\phi$估计的可信度越高。\n",
    "\n",
    "仅通过这两个引理，我们就可以推导出一些关于学习理论的深层次的至关重要的结论。\n",
    "\n",
    "为了使后面的论述更简洁，我们先将注意力限定在$y\\in\\{0,1\\}$的二元分类问题上。我们在这里讨论的结论都可以推广到包括回归、多元分类等问题中。\n",
    "\n",
    "假设有一组大小为$m$的训练集$S=\\left\\{\\left(x^{(i)},y^{(i)}\\right);i=1,\\cdots,m\\right\\}$，其中的样本$\\left(x^{(i)},y^{(i)}\\right)$服从某个独立同分布的概率分布$\\mathcal{D}$。对于假设函数$h$，我们定义**训练误差（training error）**（在学习理论中也称为**经验风险（empirical risk）**或**经验误差（empirical error）**）为：\n",
    "\n",
    "$$\n",
    "\\hat\\varepsilon(h)=\\frac{1}{m}\\sum_{i=1}^m1\\left\\{h\\left(x^{(i)}\\right)\\neq y^{(i)}\\right\\}\n",
    "$$\n",
    "\n",
    "其实就是$h$对训练集误分类的比例。如果想要明确表示$\\hat\\varepsilon(h)$是基于训练集$S$的，那么可以写作$\\hat\\varepsilon_S(h)$。我们定义一般化的误差为：\n",
    "\n",
    "$$\n",
    "\\varepsilon(h)=P_{(x,y)\\sim\\mathcal{D}}(h(x)\\neq y)\n",
    "$$\n",
    "\n",
    "这个式子表示，如果从分布$\\mathcal{D}$中再取出一个新的样本$(x,y)$，$h$会将其误分类的概率。\n",
    "\n",
    "应该留意的是，我们一直假设训数据是从分布$\\mathcal{D}$中取出的，而分布$\\mathcal{D}$正是我们将要（通过一般化的误差定义式）用假设函数$h$评估的对象。这也有时候会作为**PAC**假设中的一条。（PAC是probably approximately correct的缩写，通常译为可能近似正确，它是学习理论已经证明的一套理论框架中的一些列假设。其中最重要的是关于同一个分布的训练以及测试的假设，以及关于独立抽取训练样本的假设。）\n",
    "\n",
    "考虑线性分类的设置，令$h_\\theta(x)=1\\left\\{\\theta^Tx\\geq0\\right\\}$，那么用什么方法拟合参数$\\theta$比较合理呢？其中一种实现是通过最小化训练误差得到：\n",
    "\n",
    "$$\n",
    "\\hat\\theta=\\mathrm{arg}\\operatorname*{max}_{\\theta}\\hat\\varepsilon(h_\\theta)\n",
    "$$\n",
    "\n",
    "我们称这个算法为**经验风险最小化（ERM: empirical risk minimization）**，而由学习算法得出的假设函数为$\\hat h=h_{\\hat\\theta}$。经验风险最小化通常被认为是最基础的学习算法，它也是本节关注的焦点算法。（ERM本身是一个非凸优化问题，诸如逻辑回归和支持向量机等算法也可以被看做是一种凸性近似的经验风险最小化算法。）\n",
    "\n",
    "在深入学习理论的过程中，我们要学会不纠结于假设某些特定的参数化法或该不该使用线性分类器等问题。对于本讲要证明的结论来说，我们不再把学习算法当做是一组参数的选取过程，而应该把它当做是选择一个函数的过程。定义学**假设类（hypothesis class）$\\mathcal{H}$**是所有分类器的集合，而我们的学习算法会从中选择分类器。对于线性分类器，$\\mathcal{H}=\\left\\{h_\\theta:h_\\theta(x)=1\\left\\{\\theta^Tx\\geq0\\right\\},\\theta\\in\\mathbb{R}^{n+1}\\right\\}$是所有判别边界是线性的分类器集合，其中的每一个成员$h_\\theta$都是从$\\mathcal{X}$（输入域）到$\\{0,1\\}$的函数。更广泛的，比如我们在学习神经网络，则我们可以令$\\mathcal{H}$为表示神经网络架构的所有分类器的集合。\n",
    "\n",
    "现在可以将经验风险最小化看做是一类函数$\\mathcal{H}$中的一个最小化函数，算法将在这一类函数中选择一个假设：\n",
    "\n",
    "$$\n",
    "\\hat h=\\mathrm{arg}\\operatorname*{min}_{h\\in\\mathcal{H}}\\hat\\varepsilon(h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 若$\\mathcal{H}$是有限的\n",
    "\n",
    "我们从一个具有“由$k$个假设构成的有限假设类$\\mathcal{H}=\\{h_1,\\cdots,h_k\\}$”的学习问题开始讲起。因此$\\mathcal{H}$只是$k$个从$\\mathcal{X}$映射到$\\{0,1\\}$的函数组成的集合，而经验风险最小化将从这$k$个函数中选择训练误差最小的一个。\n",
    "\n",
    "我们想要给$h$的泛化误差加上保证条件，分为两步：\n",
    "* 我们先要证明对于所有$h$，都有$\\hat\\varepsilon(h)$是$\\varepsilon(h)$的可靠估计；\n",
    "* 接下来证明$\\hat h$的泛化误差存在一个上界。\n",
    "\n",
    "假设我们从中选了$h_i\\in\\mathcal{H}$，考虑一个如下定义的伯努利随机变量$Z$：抽取样本$(x,y)\\sim\\mathcal{D}$，然后令$Z=1\\left\\{h_i(x)=\\neq y\\right\\}$，即抽取一个样本，然后用$Z$来表示$h_i$是否误分类了样本。类似的，定义$Z_j=1\\left\\{h_i\\left(x^{(j)}\\right)\\neq y^{(i)}\\right\\}$。由于我们的训练集是$\\mathcal{D}$上的独立同分布，所以$Z$和$Z_j$具有相同的分布。\n",
    "\n",
    "可以看出对于随机抽取的样本，被误分类的概率为$\\varepsilon$（这正是$Z$和$Z_j$的预期值）。而且，训练误差可以写作：\n",
    "\n",
    "$$\n",
    "\\hat\\varepsilon(h_i)=\\frac{1}{m}\\sum_{i=1}^mZ_j\n",
    "$$\n",
    "\n",
    "$\\hat\\varepsilon(h_i)$正是$m$个随机变量$Z_j$的期望，它们是从伯努利分布中抽取的期望为$\\varepsilon(h_i)$的独立同分布的随机变量。带入霍夫丁不等式有：\n",
    "\n",
    "$$\n",
    "P\\left(\\left\\lvert \\varepsilon(h_i)-\\hat\\varepsilon(h_i)\\right\\rvert\\gt\\gamma\\right)\\leq2\\exp\\left(-2\\gamma^2m\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\left(\\right)\n",
    "\\left\\lVert\\right\\rVert\n",
    "\\begin{align}\\end{align}\n",
    "\\begin{bmatrix}\\end{bmatrix}\n",
    "\\left\\langle\\right\\rangle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
